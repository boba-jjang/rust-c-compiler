// use super::token::Token;
/*
super → go up to lexer
token → go into lexer::token
Token → the Token enum defined there
*/

pub fn scan(input: &str) { // -> Vec<Token>
    // for line in input {
    //     println!("{line}");
    // }
    println!("File content:\n{input}");
    // let mut tokens = Vec::new();

    // for word in input.split_whitespace() {
    //     tokens.push(Token::Word(word.to_string()));
    // }

    // tokens
}